{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.applications import resnet50\nimport random \nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\n\nbreeds = []\n\n# The parent directory where the images are stored\nbaseDir = '/kaggle/input/stanford-dogs-dataset-traintest/cropped'\n\n# Count the number of breeds in the dataset \nfor dirname, _, filenames in os.walk(baseDir+'/train'): \n    breed_name = dirname.split('/')[-1]\n    \n    # Skip the 'test' folder\n    if dirname in ['train', 'test']: continue\n    \n    # Remove the id from the breed_name\n    breed_name = [c for c in breed_name if c == '_' or c.isalpha()]\n    # Save the breed name as a string\n    breeds.append(''.join(breed_name))\n\n# Remove the test breed \ndel breeds[0]\nnum_breeds = len(breeds)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def load_dataset(filePath, num_samples = None): \n    images = [] \n    labels = []\n    for dirname, _, filenames in os.walk(filePath): \n        # Get the breed name \n        breed_name = dirname.split('/')[-1]\n        # Clean the breed_name \n        breed_name = ''.join([c for c in breed_name if c == '_' or c.isalpha()])\n        for index, filename in enumerate(filenames):\n            # Break the loop if length exceeds num_samples\n            if num_samples is not None: \n                if index > num_samples: \n                    break\n            # Get the extension of the file \n            ext = filename.split('.')\n            # Check if the file is an image\n            if ext[-1] != 'jpg': continue\n            img = load_img(os.path.join(dirname, filename)) \n            # Convert the image to numpy array \n            img_array = img_to_array(img)\n            # Standardize the img array \n            img_array = img_array/255\n            # Save the image\n            images.append(img_array)\n            # Save the label \n            labels.append(breed_name)\n    return images, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_train, labels_train = load_dataset(os.path.join(baseDir, 'train'), num_samples=30)\nimages_test, labels_test = load_dataset(os.path.join(baseDir, 'test'), num_samples=30)\n# Convert the lists into numpy arrays\nimages_train = np.asarray(images_train)\nimages_test = np.asarray(images_test)\n\n# Convert the labels into breed ids\nlabels_train = [breeds.index(breed) for breed in labels_train]\nlabels_test = [breeds.index(breed) for breed in labels_test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one hot encode the labels \nlabels_train = to_categorical(labels_train)\nlabels_test = to_categorical(labels_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create model from scratch (11.5% Test Accuracy)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(parameters):\n    model = Sequential() \n    \n    # First block \n    model.add(Conv2D(16, (3,3), padding='same', input_shape=parameters['input_shape']))\n    model.add(BatchNormalization(axis=3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4), padding='same'))\n    model.add(Dropout(0.2))\n    \n    # Second block \n    model.add(Conv2D(32, (3,3), padding='same'))\n    model.add(BatchNormalization(axis=3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4), padding='same'))\n    model.add(Dropout(0.2))\n    \n    # Third block \n    model.add(Conv2D(64, (3,3), padding='same'))\n    model.add(BatchNormalization(axis=3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4), padding='same'))\n    model.add(Dropout(0.2))\n    \n    # Final Block \n    model.add(Conv2D(128, (3,3), padding='same'))\n    model.add(BatchNormalization(axis=3))\n    model.add(Activation('relu'))\n  \n    # Fully connected layers\n    model.add(Flatten())\n    model.add(Dropout(0.2))\n    model.add(Dense(512, activation='relu'))\n    model.add(Dense(parameters['n'], activation='softmax'))\n    \n    if parameters['get_summary'] is True: \n        model.summary()\n    \n    return model ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a new model \nmodel = create_model({\n    'input_shape': (224,224,3), \n    'n': num_breeds, \n    'get_summary': True\n    \n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot a random image (check manually) \nindex = random.randint(0, len(images_train))\nplt.imshow(images_train[index][:,:,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the hyperparameters for the model \nnum_epochs = 10 \nbatchSize = 64\n\n# Compile the model \nmodel.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n\n# Fit the model \nprint(images_test.shape)\nmodel.fit(images_train, labels_train, \n         validation_data=(images_test, labels_test),\n         epochs=num_epochs, batch_size=batchSize, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using the ResNet-50 Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the ResNet50 Model \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}